{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Statistical Arbitrage\n",
    "\n",
    "(This notebook can be found on GitHub: https://github.com/rodler/quantinsti_statarb)\n",
    "\n",
    "### Dr Tom Starke \n",
    "\n",
    "*Homepage: www.aaaquants.com *\n",
    "\n",
    "*Email: tom@aaaquants.com *\n",
    "\n",
    "*Linkedin: Dr Tom Starke *\n",
    "\n",
    "### What we will learn:\n",
    "- Building a PCA manually\n",
    "- Conduct a pairs-trading backtest using PCA\n",
    "- Simulation of multiple cointegrated assets\n",
    "- Sector statistical arbitrage using PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import matplotlib\n",
    "from itertools import groupby, count\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short recap: cointegration versus correlation\n",
    "\n",
    "- Cointegrated price series do not necessarily have to be correlated and vice-versa \n",
    "\n",
    "- Drunk and her dog: https://www.researchgate.net/publication/254330798_A_Drunk_and_Her_Dog_An_Illustration_of_Cointegration_and_Error_Correction\n",
    "\n",
    "- Same behaviour in the markets and causality relationships change. For more information please refer to Engle-Granger causality (https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjcvKPcsqDeAhXTbCsKHTmNAe8QFjAAegQIBxAB&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FGranger_causality&usg=AOvVaw1mYq3HhcjsVNJ9zJ6zgqdV)\n",
    "\n",
    "\n",
    "Engel-Granger Causality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA) to find structure in complex systems\n",
    "https://systematicedge.wordpress.com/2013/06/02/principal-component-analysis-in-portfolio-management/\n",
    "\n",
    "- Unsupervised machine learning.\n",
    "- \"Principal components\" are \"modes\" of a system, similar to vibrational overtones of a guitar string.\n",
    "- They are eigenvectors of the covariance matrix.\n",
    "- Number of eigenvectors equals the number of features.\n",
    "- \"Dimensionality reduction\": reducing the number of eigenvectors.\n",
    "- Eigenvectors are \"orthogonal\" - uncorrelated.\n",
    "\n",
    "To illustrate this, let's produce two correlated time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random seed for consistency\n",
    "np.random.seed(20)\n",
    "\n",
    "# Produce a series as the cumulative sum of normally distributed random numbers.\n",
    "x = np.cumsum(np.random.randn(200)) + 100\n",
    "\n",
    "# Produce a second series with the same behaviour but higher standard deviation.\n",
    "y = x*2 + np.random.randn(200) - 100\n",
    "\n",
    "# Generate an array to be used in our PCA calculation.\n",
    "# Note that we have to de-mean our values first.\n",
    "R = np.array([x-np.mean(x),y-np.mean(y)])\n",
    "\n",
    "# Plot x and y\n",
    "plt.plot(x)\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For PCA we calculate the covariance matrix of R and subsequently the eigenvectors and eigenvalues. Here, the eigenvectors tell us the axis of the largest variance and the eigenvalues tell us the magnitude of the variance along each axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the covariance matrix\n",
    "S = np.cov(R)\n",
    "print('Cov Matrix:', S)\n",
    "\n",
    "# Calculate the eigenvalues and eigenvectors\n",
    "EIG = np.linalg.eig(S)\n",
    "print('Eigenvalues: ',EIG[0])\n",
    "print('Eigenvectors: ',EIG[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the vectors in space and plot our x and y values. We can see that we are capturing the direction of the largest variance. These vectors are called \"principal components\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the eigenvectors from EIG\n",
    "EV = EIG[1]\n",
    "\n",
    "# Create x-values for plotting eigenvectors\n",
    "xx = np.linspace(min(R[0,:]),max(R[0,:]),200)\n",
    "\n",
    "# Create y-values for plotting eigenvectors\n",
    "\n",
    "yy1 = (EV[1][0]/EV[0][0])*xx\n",
    "yy2 = (EV[1][1]/EV[0][1])*xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most significant eigenvector is the one with the highest eigenvalue. Here we extract its row number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_significant_factor = np.argmax(EIG[0])\n",
    "print('Most significant factor: ',most_significant_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot our de-meaned price values along with their priciple components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de-meaned x - y correlation\n",
    "plt.plot(R[0,:],R[1,:],'o')\n",
    "\n",
    "# Plot the first principal component\n",
    "plt.plot(xx,yy1,label='first')\n",
    "\n",
    "# Plot the second principal component\n",
    "plt.plot(xx,yy2,label='second')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Make sure axis are equal to illustrate orthogonality\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the two-dimensional case we get exactly two principal components. With the priciple components we can now calculate our abstract factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the factor values from the eigenvector\n",
    "factors = np.dot(EV.T,R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows how well our factors are correlated with x and y. Note that for each return curve we have two factors.\n",
    "We can see that component 1 with an eigenvalue of 84.46 has a strong correlation with x and y, component 0 with an eigenvalue of only 0.18 does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations between factors\n",
    "plt.plot(factors[0],R[0,:],'bo',label='Price 1, princomp 0')\n",
    "plt.plot(factors[1],R[1,:],'ro',label='Price 2, princomp 1')\n",
    "plt.plot(factors[0],R[1,:],'go',label='Price 2, princomp 0')\n",
    "plt.plot(factors[1],R[0,:],'ko',label='Price 1, princomp 1')\n",
    "plt.axis('equal')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Pairs Trade\n",
    "\n",
    "- The use of PCA for pairs trading and subsequent generalisation of the technique to large portfolios.\n",
    "- Produce pair of cointegrated price series.\n",
    "- Build a backtest.\n",
    "- Analyse the results.\n",
    "\n",
    "First we create an algorithm for \"drunk and dog\" cointegration. Here,\n",
    "- T are the starting values\n",
    "- Sigma are the standard deviations of each path.\n",
    "- c is a variable that determines how strongly both returns are connected.\n",
    "- if c[0] = 0 and c[1] = 0 -> both are random walks (drunk does not own dog).\n",
    "- if one c is zero and the other non-zero there is a one way causality (drunk owns dog).\n",
    "- if both c are non-zero there is two-way causality (dog sometimes pulls drunk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coint_0(N,T0=[0,0],sigma=[1,1],c=[0.1,0.1]):\n",
    "    '''\n",
    "    Algorithm from:\n",
    "    https://www.researchgate.net/publication/254330798_A_Drunk_and_Her_Dog_An_Illustration_of_Cointegration_and_Error_Correction\n",
    "    '''\n",
    "    X = [0]\n",
    "    Y = [0]\n",
    "    for i in range(N):\n",
    "        rx = np.random.randn()*sigma[0] - c[0]*(X[-1] - Y[-1])\n",
    "        ry = np.random.randn()*sigma[1] + c[1]*(X[-1] - Y[-1])\n",
    "        X.append(X[-1]+rx)\n",
    "        Y.append(Y[-1]+ry)\n",
    "    return np.array(X)+T0[0],np.array(Y)+T0[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plotting X and Y we can see that they follow each other closely.\n",
    "Now, vary c as follows and observe what happens:\n",
    "- c = [ 0.9, 0.0 ]\n",
    "- c = [ 0.1, 0.1 ]\n",
    "- c = [ 0.1, 0.9 ]\n",
    "- c = [ 0.0 , 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(452)\n",
    "X,Y = make_coint_0(200,T0=[50,50],c=[0.1,0.1])\n",
    "plt.plot(X,'r-',Y,'b-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing the quality of our cointegration:\n",
    "- Critical values for 0.1, 0.05 and 0.01.\n",
    "- T-statistic should be below crit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = coint(X,Y)\n",
    "print('Critical Values:',crit[2])\n",
    "print('T-statistic:',crit[0])\n",
    "print('P-value:',crit[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of PCA to pairs trading:\n",
    "- Use the sklearn PCA package to generate components.\n",
    "- Linear regression with the price data.\n",
    "- Z-score the residual to normalise for varying price levels and volatility.\n",
    "- Trade when residual sufficiently deviates from mean. \n",
    "- Use of log prices can help to mitigate large price swings (e.g. in penny stocks)\n",
    "\n",
    "Below the code for the PCA pairs trade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Zscore(X):\n",
    "    return np.array((X - np.mean(X)) / np.std(X))\n",
    "\n",
    "def run_pca(pr,components=1,log_prices=True):\n",
    "    \n",
    "    # Instanciate PCA \n",
    "    pca = PCA(n_components=components)\n",
    "    px = pr.T-np.mean(pr.T)\n",
    "    \n",
    "    if log_prices:\n",
    "        \n",
    "        # Calculate the priciple components using log prices\n",
    "        comps = pca.fit(np.log(pr.T)).components_.T\n",
    "        \n",
    "        # Create the factors from the pricinple components\n",
    "        factors = sm.add_constant(pr.T.dot(comps))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Calculate the N priciple components using normal prices\n",
    "        comps = pca.fit(px).components_.T\n",
    "        \n",
    "         # Create the factors from the pricinple components\n",
    "        factors = sm.add_constant(px.dot(comps))  \n",
    "        \n",
    "\n",
    "    \n",
    "    # Regress each factor with the actual underlying prices\n",
    "    mm = [sm.OLS(s.T, factors).fit() for s in pr]\n",
    "    \n",
    "    # Calculate the residuals\n",
    "    resids = list(map(lambda x: x.resid, mm))\n",
    "    \n",
    "    return resids, factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Running the PCA we can now see the factors with equal values of opposite sign.\n",
    "- Same as in \"regular\" pairs trade where opposite sign is expressed by long/short.\n",
    "- PCA gives reversible results when X and Y are switched, linear regression does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input array from cointegrated price series\n",
    "R = np.array([X,Y,X])\n",
    "\n",
    "# Run the PCA calculation\n",
    "residuals, factors = run_pca(R,log_prices=True)\n",
    "\n",
    "# Plot the residuals\n",
    "plt.plot(residuals[0],label='resid X')\n",
    "plt.plot(residuals[1],label='resid Y')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('residuals')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side-node, observe that linear regression is not reversible.\n",
    "- Residuals are calculated as distances to fitting line along to y-axis.\n",
    "- In PCA residuals are calculated orthogonal to principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.polyfit(X,Y,1)[0]\n",
    "m_rev = np.polyfit(Y,X,1)[0]\n",
    "print('Slope of regression:',m)\n",
    "print('Inverse slope of reverse regression:',1/m_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairs-Trade Backtest\n",
    "- Sequentially step through time and instruments.\n",
    "- Calculate if z-score of residuals is large enough to trade.\n",
    "- If in trade, see if residuals have mean reverted enough to exit.\n",
    "- Calculate the pnl.\n",
    "\n",
    "(For simplicity we calculate the residuals first, thus introducing a forward-looking bias. This is to make the calcs faster and it is rectified later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpos = np.zeros(R.shape[0]) # side: long=+1; short=-1\n",
    "pnl = [0] # PnL vector\n",
    "bw = 2 # z-score threshold (bandwidth)\n",
    "op = {} # dict of entry prices\n",
    "\n",
    "# loop through time steps\n",
    "for i in range(len(residuals[0])):\n",
    "    p = 0 # initialise pnl-calc for a particular time step\n",
    "    \n",
    "    # loop through instruments\n",
    "    for inst in range(R.shape[0]):\n",
    "        \n",
    "        # calculate the z-score of residuals\n",
    "        zs = Zscore(residuals[inst])[i]\n",
    "        \n",
    "        # Entry condition: z-score above bandwith and no position on\n",
    "        if np.abs(zs)>bw and inpos[inst] == 0:\n",
    "            op[inst] = R[inst,i] # record the open price\n",
    "            inpos[inst] = zs  # tell algo that we have a position\n",
    "            \n",
    "        # Exit condition: z-score has crossed zero and position on\n",
    "        elif zs*np.sign(inpos[inst])<0:\n",
    "            \n",
    "            # Calculate pnl as (exit-entry)*side\n",
    "            p+=((-R[inst,i]+op[inst])*np.sign(inpos[inst]))\n",
    "            inpos[inst] = 0 # set side to zero\n",
    "    \n",
    "    # append the new pnl to vector\n",
    "    pnl.append(p)\n",
    "    \n",
    "# Plot the results of the backtest\n",
    "plt.plot(np.cumsum(pnl),'-')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('realised PnL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate sector cointegration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simulated time series provide understandable results. \n",
    "- Stocks within a sector are often cointegrated.\n",
    "- Maths of \"Drunk and her dog\" generalisation shown below:\n",
    "\n",
    "\\begin{align}\n",
    "c_{ij} = \\Bigg\\{ \n",
    "\\begin{split}\n",
    "-a_{ij} \\quad for \\quad i \\leq j \\\\ \n",
    "a_{ij} \\quad for \\quad i \\geq j \\\\ \n",
    "-a_{ij} \\quad for \\quad i = j\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "X_{t}^{(i)}-X_{t-1}^{(i)} = \\sum_{j} c_{ij} X_{t-1}^{(j)} + \\epsilon_{i} \\quad with \\quad a_{ij} \\geq 0\n",
    "\\end{align}\n",
    "\n",
    "- *X* denotes the time series, *c* is the causality matrix.\n",
    "- *a* are the positive elements of the causality matrix. \n",
    "\n",
    "(Note that the *a's* denote the relationships between different series. We can simply use random numbers to start with. As we increase the number of series, we need to keep *a* small to avoid positive feedback scenarios.) \n",
    "\n",
    "Below the code that implements the above equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coint_1(N,steps,a=0.1):\n",
    "    X = [np.zeros(N)]\n",
    "    \n",
    "    # Create the causality matrix\n",
    "    c = (np.tril(np.ones(N))-np.triu(np.ones(N))-np.diag(np.ones(N),0))*a #c = np.random.rand(N,N)*0.1\n",
    "\n",
    "    # loop through time steps\n",
    "    for i in range(steps):\n",
    "        \n",
    "        # Calculate the returns for each time series\n",
    "        rx = (np.sum(c*X[-1],axis=1)+np.random.randn(N))\n",
    "        \n",
    "        # Add the new return to the last price of the time series\n",
    "        X.append(X[-1]+rx)\n",
    "        \n",
    "    # return array of all series\n",
    "    return np.array(X).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a cointegrated pair with this technique.\n",
    "\n",
    "__Play with this by varying *a* and observe the results.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "N = 3\n",
    "a1 = 0.1 # general case\n",
    "a2=[[0.02,0.1],[0.1,0.02]] # for N = 2\n",
    "a3=[[0.06,0.04,0.08],[0.06,0.06,0.04],[0.06,0.08,0.04]] # for N = 3\n",
    "X1 = make_coint_1(N,200,a=a1).T\n",
    "\n",
    "for i in range(N):\n",
    "    plt.plot(X1[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we have produced a set of stationary time series, testing for cointegration we see that most of them are below the critical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Critical values:',coint(X1.T[0],X1.T[1])[2])\n",
    "for i in range(X1.T.shape[0]):\n",
    "    for k in range(i,X1.T.shape[0]):\n",
    "        if not i==k:\n",
    "            print('t-stats for coint of series %s and %s:'%(i,k), coint(X1.T[i],X1.T[k])[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply our statistical arbitrage system to a simple long/short pair in order to test if our system is working properly. First, let's produce a cointegrated time series and plot it to confirm its properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Portfolio Trading\n",
    "\n",
    "- Application of strategy to larger portfolio.\n",
    "- Careful with the causality coefficients as large numbers of strong cross-dependencies can create positive feedback loops between the series. \n",
    "- Larger N - higher to probability of the feedack loops for a given *alpha*.\n",
    "\n",
    "__Please vary alpha in this exercise and observe how the behaviour of our time series changes.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(231)\n",
    "N = 10\n",
    "alpha = 0.06\n",
    "X2 = make_coint_1(N,300,a=np.random.rand(N,N)*alpha) + 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X2:\n",
    "    plt.plot(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative explained variance\n",
    "\n",
    "- 3 principle components explain 75% of variance\n",
    "- Too many components lead to very high correlation and very small PnL/trade\n",
    "- Enough PnL/trade to overcome trading costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(np.log(X2))\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.plot(np.cumsum(pca.explained_variance_)/np.sum(pca.explained_variance_),'-o')\n",
    "plt.grid()\n",
    "plt.xlabel('Component')\n",
    "plt.ylabel('Explained Variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Useful to look at the average t-statistics between all possible pairs.\n",
    "- High average t-stats - good probability of strategy success.\n",
    "- Johansen test tends to perform poorly out-of-sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cointegration test:\n",
    "coints = []\n",
    "print('Critical values:',coint(X2[0],X2[1])[2])\n",
    "for i in range(X2.shape[0]):\n",
    "    for k in range(i,X2.shape[0]):\n",
    "        if not i==k:\n",
    "            coints.append(coint(X2[i],X2[k])[0])\n",
    "            \n",
    "print('Average coint t-stats:',np.mean(coints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simulated data can give us an understanding how well our backtest performs under idealised conditions. \n",
    "\n",
    "- In the next part we are looking at applying this algorithm to real market data using Quantopian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector-portfolio backtest\n",
    "\n",
    "There are many strategies we can deploy based on our techniques such as:\n",
    "- sort the z-scores of our factors and go long the lowest and short the N assets with the highest z-scores. \n",
    "- scale the position size of each instrument according to z-score.\n",
    "- only rebalance portfolio when sum of z-scores exceeds a threshold.\n",
    "\n",
    "All of them have their uses and they need to be tested on a case-by-case basis. Here, we choose the first example as shown below. This time we eliminate the forward-looking bias by recalculating the residuals at every time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata = pickle.load(open('marketdata.pick','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pr = np.array(mdata).T#[:12,:]\n",
    "max_pos=3\n",
    "num_factors=3\n",
    "initial_cash=1e6\n",
    "\n",
    "entry = {} # create a vector of entry prices\n",
    "pnls = [] # create a pnl vector\n",
    "\n",
    "# Exit if we specified too large long/short position size\n",
    "if max_pos > pr.shape[0]/2:\n",
    "    print('max_pos too large!')\n",
    "    adfadsf\n",
    "\n",
    "# loop through the prices\n",
    "for i,pri in enumerate(pr.T):\n",
    "\n",
    "    # Make sure you have enough data points for PCA\n",
    "    if i < 50: continue\n",
    "\n",
    "    # Run the PCA, only on the past prices\n",
    "    resids, factors = run_pca(pr.T[max([0,i-400]):i],num_factors,log_prices=False)\n",
    "    zs = {}\n",
    "\n",
    "    # Calculate the z-scores for each instrument. \n",
    "    for inst in range(len(pri)):\n",
    "        try: zs[inst] = Zscore(resids[inst])[-1]\n",
    "        except: pass\n",
    "\n",
    "    pnl = 0\n",
    "    # Calculate the Pnl for each position over the prevoius period\n",
    "    for j,idx in enumerate(entry):\n",
    "\n",
    "        # Calculate the position size\n",
    "        # The sign of the position depends on the sign of the entry price\n",
    "        pos = np.round((initial_cash/len(pri))/entry[idx])\n",
    "\n",
    "        # Add up the pnls for all positions for the last period\n",
    "        # We neutralize the sign of the entry price and let it \n",
    "        # come in through the position.\n",
    "        pnl += (pri[idx]-np.abs(entry[idx]))*pos\n",
    "    pnls.append(pnl)\n",
    "\n",
    "    # Reset the portfolio\n",
    "    entry = {}\n",
    "\n",
    "    # Find the new instruments to be traded based on their z-scores\n",
    "    idx_long = (np.argsort([zs[j] for j in zs])[:max_pos])\n",
    "    idx_short = (np.argsort([zs[j] for j in zs])[-max_pos:])\n",
    "\n",
    "    # Add them to the entry list\n",
    "    # The entry gets a positive or negative sign depending on the side of the trade\n",
    "    for idx in idx_long:\n",
    "        entry[idx] = pri[idx]\n",
    "    for idx in idx_short:\n",
    "        entry[idx] = -pri[idx]\n",
    "\n",
    "    print(i,sum(pnls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pickle.load(open('pnls.pick','rb'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "tribo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
